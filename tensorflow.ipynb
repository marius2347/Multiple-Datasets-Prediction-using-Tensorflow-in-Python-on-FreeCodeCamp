{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> TENSORFLOW MACHINE LEARNING </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 01:10:10.898201: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-24 01:10:10.921870: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-24 01:10:10.921897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-24 01:10:10.922579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-24 01:10:10.926729: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-24 01:10:10.927612: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-24 01:10:11.616546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# CORE ALGORITHMS\n",
    "\n",
    "# importing modules\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# load dataset.\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the first 5 rows\n",
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_9881/784288811.py:10: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_9881/784288811.py:13: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# training the feature columns\n",
    "\n",
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)) # associate every feature name with a list of unique vocabulary\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS: \n",
    "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32)) # for the ones with numerical features\n",
    "\n",
    "\n",
    "# print it\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training process - Input Function\n",
    "def make_input_fn(data_df, label_df, num_epochs = 10, shuffle = True, batch_size = 32):\n",
    "    def input_function(): # inner function, this will be returned\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df)) # creates dataset object with data and its features\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000) # randomize the data\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs) # split dataset into baches of 32 and repeat the process of num of epochs\n",
    "        return ds # return the batch dataset\n",
    "    return input_function # return a function to use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train) # get a dataset to train\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs = 1, shuffle = False) # for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7613636\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "linear_est = tf.estimator.LinearClassifier(feature_columns = feature_columns)\n",
    "\n",
    "# Training the model\n",
    "linear_est.train(train_input_fn) # train the model\n",
    "result = linear_est.evaluate(eval_input_fn) # testing the model\n",
    "clear_output() # clear the console for useless training outputs\n",
    "print(result['accuracy']) # see the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                          male\n",
      "age                          35.0\n",
      "n_siblings_spouses              0\n",
      "parch                           0\n",
      "fare                         8.05\n",
      "class                       Third\n",
      "deck                      unknown\n",
      "embark_town           Southampton\n",
      "alone                           y\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# dictionary of one prediction\n",
    "print(dfeval.loc[0]) # print the person\n",
    "# print(result[0]['probabilities'][1]) # change of survival: index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result[0]['probabilities'][0]) # change of not survival: index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_eval.loc[0]) # if they survive or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Lets define some constants to help us later on\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the species column and use that as our label\n",
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.head() # the species column is gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head() # species stored in train_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of our train model\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Function\n",
    "def input_fn(features, labels, training = True, batch_size = 256):\n",
    "    # converts the inputs to a Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # shuffle (random) and repeat \n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature Columns\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key = key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_9881/4009718890.py:4: DNNClassifierV2.__init__ (from tensorflow_estimator.python.estimator.canned.dnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /home/marius/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/head/head_utils.py:59: MultiClassHead.__init__ (from tensorflow_estimator.python.estimator.head.multi_class_head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp9rj7ello\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp9rj7ello', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Building the Model\n",
    "\n",
    "# build a DNN with 2 hidden layers (30 and 10 hidden nodes each)\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns = my_feature_columns, hidden_units = [30, 10], n_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marius/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/estimator.py:385: StopAtStepHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp9rj7ello/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 01:10:15.973129: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'dnn/zero_fraction/cond/output/_18'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4259735, step = 0\n",
      "INFO:tensorflow:global_step/sec: 379.049\n",
      "INFO:tensorflow:loss = 1.0081897, step = 100 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.116\n",
      "INFO:tensorflow:loss = 0.92539084, step = 200 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.85\n",
      "INFO:tensorflow:loss = 0.8746515, step = 300 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.609\n",
      "INFO:tensorflow:loss = 0.8423934, step = 400 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.159\n",
      "INFO:tensorflow:loss = 0.81535673, step = 500 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.794\n",
      "INFO:tensorflow:loss = 0.7834702, step = 600 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.045\n",
      "INFO:tensorflow:loss = 0.7601323, step = 700 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.505\n",
      "INFO:tensorflow:loss = 0.73946476, step = 800 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.693\n",
      "INFO:tensorflow:loss = 0.71955025, step = 900 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.455\n",
      "INFO:tensorflow:loss = 0.7058193, step = 1000 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.438\n",
      "INFO:tensorflow:loss = 0.6926456, step = 1100 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.588\n",
      "INFO:tensorflow:loss = 0.67808664, step = 1200 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.231\n",
      "INFO:tensorflow:loss = 0.6660347, step = 1300 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.331\n",
      "INFO:tensorflow:loss = 0.65166855, step = 1400 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.782\n",
      "INFO:tensorflow:loss = 0.64116156, step = 1500 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.841\n",
      "INFO:tensorflow:loss = 0.6379516, step = 1600 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.458\n",
      "INFO:tensorflow:loss = 0.6213557, step = 1700 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.361\n",
      "INFO:tensorflow:loss = 0.6132847, step = 1800 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.6\n",
      "INFO:tensorflow:loss = 0.6013541, step = 1900 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.386\n",
      "INFO:tensorflow:loss = 0.59134924, step = 2000 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.281\n",
      "INFO:tensorflow:loss = 0.5878774, step = 2100 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.418\n",
      "INFO:tensorflow:loss = 0.57688403, step = 2200 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.892\n",
      "INFO:tensorflow:loss = 0.5806594, step = 2300 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.149\n",
      "INFO:tensorflow:loss = 0.5611861, step = 2400 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.562\n",
      "INFO:tensorflow:loss = 0.5529462, step = 2500 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.923\n",
      "INFO:tensorflow:loss = 0.5452431, step = 2600 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.637\n",
      "INFO:tensorflow:loss = 0.54727733, step = 2700 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.9\n",
      "INFO:tensorflow:loss = 0.54445595, step = 2800 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.554\n",
      "INFO:tensorflow:loss = 0.5262197, step = 2900 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.224\n",
      "INFO:tensorflow:loss = 0.5298211, step = 3000 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.551\n",
      "INFO:tensorflow:loss = 0.5241208, step = 3100 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.538\n",
      "INFO:tensorflow:loss = 0.51873213, step = 3200 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.13\n",
      "INFO:tensorflow:loss = 0.5082559, step = 3300 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.43\n",
      "INFO:tensorflow:loss = 0.4938672, step = 3400 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.952\n",
      "INFO:tensorflow:loss = 0.5002488, step = 3500 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.562\n",
      "INFO:tensorflow:loss = 0.48685244, step = 3600 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.03\n",
      "INFO:tensorflow:loss = 0.48887715, step = 3700 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.662\n",
      "INFO:tensorflow:loss = 0.47684187, step = 3800 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.829\n",
      "INFO:tensorflow:loss = 0.46539536, step = 3900 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.318\n",
      "INFO:tensorflow:loss = 0.45942077, step = 4000 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.079\n",
      "INFO:tensorflow:loss = 0.46483806, step = 4100 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.191\n",
      "INFO:tensorflow:loss = 0.45818692, step = 4200 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.354\n",
      "INFO:tensorflow:loss = 0.453131, step = 4300 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.449\n",
      "INFO:tensorflow:loss = 0.44593984, step = 4400 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.317\n",
      "INFO:tensorflow:loss = 0.4488891, step = 4500 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.242\n",
      "INFO:tensorflow:loss = 0.44593793, step = 4600 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.327\n",
      "INFO:tensorflow:loss = 0.4490679, step = 4700 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.545\n",
      "INFO:tensorflow:loss = 0.432646, step = 4800 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.267\n",
      "INFO:tensorflow:loss = 0.43059316, step = 4900 (0.233 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp9rj7ello/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.42981803.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fd7e4283f70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model\n",
    "classifier.train(\n",
    "    input_fn = lambda: input_fn(train, train_y, training = True), steps = 5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-12-24T01:10:28\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9rj7ello/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.13156s\n",
      "INFO:tensorflow:Finished evaluation at 2023-12-24-01:10:28\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.7, average_loss = 0.5097641, global_step = 5000, loss = 0.5097641\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmp9rj7ello/model.ckpt-5000\n",
      "\n",
      "Test set accuracy:  0.700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the Model\n",
    "\n",
    "eval_result = classifier.evaluate(input_fn = lambda: input_fn(test, test_y, training = False))\n",
    "print('\\nTest set accuracy: {accuracy: 0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/marius/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/head/base_head.py:786: ClassificationOutput.__init__ (from tensorflow.python.saved_model.model_utils.export_output) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /home/marius/.local/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/head/multi_class_head.py:455: PredictOutput.__init__ (from tensorflow.python.saved_model.model_utils.export_output) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9rj7ello/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Virginica\" (94.9%)\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    # convert the inputs to a Dataset without labels\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features:\n",
    "  valid = True\n",
    "  while valid: \n",
    "    val = input(feature + \": \")\n",
    "    if not val.isdigit(): valid = False\n",
    "\n",
    "  predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
